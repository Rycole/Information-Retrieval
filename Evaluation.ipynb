{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Evaluation Notebook\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import math\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Importing the Dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>symbols</th>\n",
       "      <th>company_names</th>\n",
       "      <th>url</th>\n",
       "      <th>verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.019700e+18</td>\n",
       "      <td>VIDEO: “I was in my office. I was minding my o...</td>\n",
       "      <td>Wed Jul 18 21:33:26 +0000 2018</td>\n",
       "      <td>GoldmanSachs</td>\n",
       "      <td>GS</td>\n",
       "      <td>The Goldman Sachs</td>\n",
       "      <td>https://twitter.com/i/web/status/1019696670777...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.019710e+18</td>\n",
       "      <td>The price of lumber $LB_F is down 22% since hi...</td>\n",
       "      <td>Wed Jul 18 22:22:47 +0000 2018</td>\n",
       "      <td>StockTwits</td>\n",
       "      <td>M</td>\n",
       "      <td>Macy's</td>\n",
       "      <td>https://twitter.com/i/web/status/1019709091038...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.019710e+18</td>\n",
       "      <td>Who says the American Dream is dead? https://t...</td>\n",
       "      <td>Wed Jul 18 22:32:01 +0000 2018</td>\n",
       "      <td>TheStreet</td>\n",
       "      <td>AIG</td>\n",
       "      <td>American</td>\n",
       "      <td>https://buff.ly/2L3kmc4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.019720e+18</td>\n",
       "      <td>Barry Silbert is extremely optimistic on bitco...</td>\n",
       "      <td>Wed Jul 18 22:52:52 +0000 2018</td>\n",
       "      <td>MarketWatch</td>\n",
       "      <td>BTC</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>https://twitter.com/i/web/status/1019716662587...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.019720e+18</td>\n",
       "      <td>How satellites avoid attacks and space junk wh...</td>\n",
       "      <td>Wed Jul 18 23:00:01 +0000 2018</td>\n",
       "      <td>Forbes</td>\n",
       "      <td>ORCL</td>\n",
       "      <td>Oracle</td>\n",
       "      <td>http://on.forbes.com/6013DqDDU</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text  \\\n",
       "0  1.019700e+18  VIDEO: “I was in my office. I was minding my o...   \n",
       "1  1.019710e+18  The price of lumber $LB_F is down 22% since hi...   \n",
       "2  1.019710e+18  Who says the American Dream is dead? https://t...   \n",
       "3  1.019720e+18  Barry Silbert is extremely optimistic on bitco...   \n",
       "4  1.019720e+18  How satellites avoid attacks and space junk wh...   \n",
       "\n",
       "                        timestamp        source symbols      company_names  \\\n",
       "0  Wed Jul 18 21:33:26 +0000 2018  GoldmanSachs      GS  The Goldman Sachs   \n",
       "1  Wed Jul 18 22:22:47 +0000 2018    StockTwits       M             Macy's   \n",
       "2  Wed Jul 18 22:32:01 +0000 2018     TheStreet     AIG           American   \n",
       "3  Wed Jul 18 22:52:52 +0000 2018   MarketWatch     BTC            Bitcoin   \n",
       "4  Wed Jul 18 23:00:01 +0000 2018        Forbes    ORCL             Oracle   \n",
       "\n",
       "                                                 url  verified  \n",
       "0  https://twitter.com/i/web/status/1019696670777...      True  \n",
       "1  https://twitter.com/i/web/status/1019709091038...      True  \n",
       "2                            https://buff.ly/2L3kmc4      True  \n",
       "3  https://twitter.com/i/web/status/1019716662587...      True  \n",
       "4                     http://on.forbes.com/6013DqDDU      True  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"https://www.kaggle.com/davidwallach/financial-tweets\"\n",
    "\n",
    "df = pd.read_csv('stockerbot-export(Verified Tweets).csv',error_bad_lines=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Text Processing\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "\n",
    "def remove_emojis(text: str) -> str:\n",
    "    return ''.join(c for c in text if c not in emoji.UNICODE_EMOJI)\n",
    "\n",
    "df2 = df.copy(deep=True)\n",
    "df2['tokens'] = df2['text'] \n",
    "df2.tokens = df2.tokens.str.lower()\n",
    "df2.tokens = df2.tokens.apply(lambda x: re.sub(r'https?:\\/\\/\\S+', '', x))\n",
    "df2.tokens = df2.tokens.apply(lambda x: re.sub(r\"www\\.[a-z]?\\.?(com)+|[a-z]+\\.(com)\", '', x))\n",
    "df2.tokens = df2.tokens.apply(lambda x: re.sub(r'{link}', '', x))\n",
    "df2.tokens = df2.tokens.apply(lambda x: re.sub(r\"\\[video\\]\", '', x))\n",
    "df2.tokens = df2.tokens.apply(lambda x: re.sub(r'&[a-z]+;', '', x))\n",
    "# df2.tokens = df2.tokens.apply(lambda x: re.sub(r\"[^a-z\\s\\d\\(\\-:\\)\\\\\\/\\!?];='#$]\", '', x))\n",
    "df2.tokens = df2.tokens.apply(lambda x: re.sub(r'[@$#]+', '', x))\n",
    "df2.tokens = df2.tokens.apply(lambda x: re.sub(\"([^\\x00-\\x7F])+\",\" \",x))  #Removed Chinese symbols\n",
    "##Removes all non-english charaters inlcuidng emojis \n",
    "df2.tokens = df2.tokens.apply(remove_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = df2['tokens'].values.tolist()  #processed tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize documents (tweets)\n",
    "document_terms = [doc.split(' ') for doc in documents]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "39Tyx4Y2sbpS"
   },
   "outputs": [],
   "source": [
    "# vectorize and get vocabulary\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "documents_vectorized = vectorizer.fit_transform(documents)\n",
    "vocabulary = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "aztwodZ76i6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have a 363 document corpus with a 2563 term vocabulary\n"
     ]
    }
   ],
   "source": [
    "print ('We have a {} document corpus with a {} term vocabulary'.format(*documents_vectorized.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "x7K-92gK93td"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>0000</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>06m</th>\n",
       "      <th>07</th>\n",
       "      <th>...</th>\n",
       "      <th>yoy</th>\n",
       "      <th>ytd</th>\n",
       "      <th>yum</th>\n",
       "      <th>zero</th>\n",
       "      <th>zim</th>\n",
       "      <th>zimbabwe</th>\n",
       "      <th>zolmaxnews</th>\n",
       "      <th>zto</th>\n",
       "      <th>zts</th>\n",
       "      <th>zuckerberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2563 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  0000  01  02  03  04  05  06  06m  07  ...  yoy  ytd  yum  zero  zim  \\\n",
       "0   0     0   0   0   0   0   0   0    0   0  ...    0    0    0     0    0   \n",
       "1   0     0   0   0   0   0   0   0    0   0  ...    0    1    0     0    0   \n",
       "2   0     0   0   0   0   0   0   0    0   0  ...    0    0    0     0    0   \n",
       "3   0     0   0   0   0   0   0   0    0   0  ...    0    0    0     1    0   \n",
       "4   0     0   0   0   0   0   0   0    0   0  ...    0    0    0     0    0   \n",
       "\n",
       "   zimbabwe  zolmaxnews  zto  zts  zuckerberg  \n",
       "0         0           0    0    0           0  \n",
       "1         0           0    0    0           0  \n",
       "2         0           0    0    0           0  \n",
       "3         0           0    0    0           0  \n",
       "4         0           0    0    0           0  \n",
       "\n",
       "[5 rows x 2563 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is what it looks like\n",
    "df3 = pd.DataFrame(documents_vectorized.toarray(), columns=vocabulary)\n",
    "doc_ids = df3.index.values\n",
    "df3[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Queries and Real Judgement\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating the queries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "aZRbOm_t-WOJ"
   },
   "outputs": [],
   "source": [
    "# In order to evaluate a search engine over this data we need two things:\n",
    "# 1. Queries\n",
    "# 2. Relevance Judgements\n",
    "\n",
    "# QUERIES dictionary with {q_id: query}\n",
    "queries = dict(enumerate([\n",
    "    'google amazon',\n",
    "    'stocks bitcoin',]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating the real judgment list showing which tweets contain the queries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "x7K-92gK93td"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0, 0), (0, 1, 0), (0, 2, 0), (0, 3, 0), (0, 4, 0)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Query 1 - 'google amazon'  ###\n",
    "\n",
    "df_test = pd.concat([df3['google'], df3['amazon']], axis = 1)\n",
    "\n",
    "def relevance1(row):\n",
    "    if row.google + row.amazon > 0: return 1\n",
    "    else: return 0\n",
    "\n",
    "    \n",
    "df_test= df_test.reset_index().assign(q_id = 0).assign(relevance = df_test.apply(relevance1, axis= 1))\n",
    "df_test.rename(columns={\"index\": \"doc_id\"}, inplace= True)\n",
    "df2_test = df_test.drop(columns=['google', 'amazon'])\n",
    "df2_test = df2_test[[\"q_id\", \"doc_id\", \"relevance\"]]\n",
    "records = df2_test.to_records(index=False)\n",
    "\n",
    "# REL JUDGEMENTS list with [(q_id, d_id, judg), ...] judg 0 | 1 with 1 = relevant\n",
    "list1 = list(records)\n",
    "list1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0, 0), (1, 1, 0), (1, 2, 0), (1, 3, 1), (1, 4, 0)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Query 2 - 'stocks bitcoin'  ###\n",
    "df_test3 = pd.concat([df3['stocks'], df3['bitcoin']], axis = 1)\n",
    "\n",
    "def relevance2(row):\n",
    "    if row.stocks + row.bitcoin > 0: return 1\n",
    "    else: return 0\n",
    "    \n",
    "df_test3 =df_test3.reset_index().assign(q_id = 1).assign(relevance = df_test3.apply(relevance2, axis= 1))\n",
    "df_q2= df_test3.drop(columns = ['stocks','bitcoin'])\n",
    "df_q2.rename(columns={\"index\": \"doc_id\"}, inplace= True)\n",
    "df_q2 = df_q2[[\"q_id\", \"doc_id\", \"relevance\"]]\n",
    "records2 = df_q2.to_records(index=False)\n",
    "\n",
    "# REL JUDGEMENTS list with [(q_id, d_id, judg), ...] judg 0 | 1 with 1 = relevant\n",
    "list2 = list(records2)\n",
    "list2[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "726"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The complete real judgemnt list for both queries.\n",
    "qrels = list1+list2\n",
    "len(qrels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Implementing BM25\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "BCUowQXp_Oz2"
   },
   "outputs": [],
   "source": [
    "def BM25_IDF_df(df):\n",
    "    \"\"\"\n",
    "    This definition calculates BM25-IDF weights before hand as done last week\n",
    "    \"\"\"\n",
    "\n",
    "    dfs = (df > 0).sum(axis=0)\n",
    "    N = df.shape[0]\n",
    "    idfs = -np.log(dfs / N)\n",
    "\n",
    "    k_1 = 1.2\n",
    "    b = 0.8\n",
    "    dls = df.sum(axis=1) \n",
    "    avgdl = np.mean(dls)\n",
    "\n",
    "    numerator = np.array((k_1 + 1) * df)\n",
    "    denominator = np.array(k_1 *((1 - b) + b * (dls / avgdl))).reshape(N,1) + np.array(df)\n",
    "\n",
    "    BM25_tf = numerator / denominator\n",
    "\n",
    "    idfs = np.array(idfs)\n",
    "\n",
    "    BM25_score = BM25_tf * idfs\n",
    "    return pd.DataFrame(BM25_score, columns=vocabulary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "4-gOELhRFI6K"
   },
   "outputs": [],
   "source": [
    "#Calling the BM25 function\n",
    "bm25_df = BM25_IDF_df(df3) # a dataframe with BM25-idf weights\n",
    "# bm25_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "f_M7mYeq_mQ4"
   },
   "outputs": [],
   "source": [
    "#Function to return ranked documents\n",
    "def retrieve_ranking(query, bm25_df):\n",
    "    q_terms = query.split(' ')\n",
    "    q_terms_only = bm25_df[q_terms]\n",
    "    score_q_d = q_terms_only.sum(axis=1)\n",
    "    return sorted(zip(bm25_df.index.values,score_q_d.values), key = lambda tup:tup[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Evaluation Functions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "RVvk4oG8HxEL"
   },
   "outputs": [],
   "source": [
    "def precision_at_k(doc_ranking, qrels, query_id, k=5):\n",
    "    retrieved = [doc[0] for doc in doc_ranking[:k]] # take only the document id, rather than score\n",
    "\n",
    "    qrels_query = [qrel for qrel in qrels if qrel[0] == query_id]\n",
    "    relevant_doc_ids = [qrel[1] for qrel in qrels_query if qrel[-1] == 1]\n",
    "    non_relevant_doc_ids = [qrel[1] for qrel in qrels_query if qrel[-1] == 0]\n",
    "\n",
    "    TP = len(set(retrieved) & set(relevant_doc_ids))\n",
    "    FP = len(set(retrieved) & set(non_relevant_doc_ids))\n",
    "    FN = len(set(relevant_doc_ids) - set(retrieved))\n",
    "\n",
    "#     try:\n",
    "    precision = TP / (TP + FP)\n",
    "#     except ZeroDivisionError:\n",
    "#         precision = 0\n",
    "        \n",
    "    recall = TP / (TP + FN)\n",
    "\n",
    "    return TP, FP, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Zawr4IYmK7OR"
   },
   "outputs": [],
   "source": [
    "def f1_score_at_k(doc_ranking, qrels, query_id, k=5):\n",
    "    # calculate f_1 score\n",
    "    # hint: you need to find TP's etc in a similar way to precision at k\n",
    "    retrieved = [doc[0] for doc in doc_ranking[:k]] # take only the document id, rather than score\n",
    "\n",
    "    qrels_query = [qrel for qrel in qrels if qrel[0] == query_id]\n",
    "    relevant_doc_ids = [qrel[1] for qrel in qrels_query if qrel[-1] == 1]\n",
    "    non_relevant_doc_ids = [qrel[1] for qrel in qrels_query if qrel[-1] == 0]\n",
    "\n",
    "    TP = len(set(retrieved) & set(relevant_doc_ids))\n",
    "    FP = len(set(retrieved) & set(non_relevant_doc_ids))\n",
    "    FN = len(set(relevant_doc_ids) - set(retrieved))\n",
    "\n",
    "#     try:\n",
    "    precision = TP / (TP + FP)\n",
    "#     except ZeroDivisionError:\n",
    "#     precision = 0\n",
    "        \n",
    "#     try:\n",
    "    recall = TP / (TP + FN)\n",
    "#     except ZeroDivisionError:\n",
    "#         recall = 0\n",
    "\n",
    "#     try:\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "#     except ZeroDivisionError:\n",
    "#         f1 = 0\n",
    "        \n",
    "    return f1\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Recall(doc_ranking, qrels, query_id):\n",
    "    retrieved = [doc[0] for doc in doc_ranking] # take only the document id, rather than score\n",
    "\n",
    "    qrels_query = [qrel for qrel in qrels if qrel[0] == query_id]\n",
    "    relevant_doc_ids = [qrel[1] for qrel in qrels_query if qrel[-1] == 1]\n",
    "    non_relevant_doc_ids = [qrel[1] for qrel in qrels_query if qrel[-1] == 0]\n",
    "\n",
    "    TP = len(set(retrieved) & set(relevant_doc_ids))\n",
    "    FP = len(set(retrieved) & set(non_relevant_doc_ids))\n",
    "    FN = len(set(relevant_doc_ids) - set(retrieved))\n",
    "\n",
    "    recall = TP / (TP + FN)\n",
    "#\n",
    "        \n",
    "    return recall\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Evaluation Calculations\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ClS7o7BPATq0",
    "outputId": "e49a74a7-52e1-485d-9d69-030c1af868cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved query \"google amazon\" with Precision@5 = 1.0 and F1-score = 0.47619047619047616\n",
      "retrieved query \"stocks bitcoin\" with Precision@5 = 1.0 and F1-score = 0.3448275862068966\n"
     ]
    }
   ],
   "source": [
    "# To retrieve and calculate accuracy metrics for each query lets loop over them\n",
    "k = 5\n",
    "for query_id, query in queries.items():\n",
    "#     print(query_id)\n",
    "#     print(query)\n",
    "    doc_ranking = retrieve_ranking(query, bm25_df)\n",
    "#     print(doc_ranking)\n",
    "\n",
    "    tp, fp, precision = precision_at_k(doc_ranking, qrels, query_id, k=k)\n",
    "    f1_score = f1_score_at_k(doc_ranking, qrels, query_id, k=k)\n",
    "    print('retrieved query \"{}\" with Precision@{} = {} and F1-score = {}'.format(query, k, precision, f1_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved query \"google amazon\" with Recall = 1.0\n",
      "retrieved query \"stocks bitcoin\" with Recall = 1.0\n"
     ]
    }
   ],
   "source": [
    "for query_id, query in queries.items():\n",
    "#     print(query_id)\n",
    "#     print(query)\n",
    "    doc_ranking = retrieve_ranking(query, bm25_df)\n",
    "#     print(doc_ranking)\n",
    "\n",
    "    recall = Recall(doc_ranking, qrels, query_id)\n",
    "    print('retrieved query \"{}\" with Recall = {}'.format(query, recall))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
